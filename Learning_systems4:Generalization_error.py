import numpy as np
import math
import pandas as pd
import matplotlib.pyplot as plt
import decimal

N = np.linspace(2,10000,num=5000)
d_vc = 50
delta = 0.05

# VC_bound
vc_bound = np.sqrt(8/N * np.log(4*((2*N)**d_vc+1)/delta))

# Rademacher Penalty bound
Rademacher = np.sqrt(2*np.log(2*N*(N**d_vc+1))/N) + np.sqrt(2/N*np.log(1/delta))+1/N

# Algorithm to get the generalization error for Parrondo and Van den Broek
e = Rademacher[4999] # initialize the error with the generalization error of Rademacher with N = 10000
Parrondo_Broek = np.sqrt(1/N*(2*e + np.log(6*((2*N)**d_vc+1)/delta)))
while Parrondo_Broek[4999]<e:
#     print("Generalization error of Parrondo_Broek is smaller than your e")
    e = Parrondo_Broek[4999]
    Parrondo_Broek = np.sqrt((2*e + np.log(6*((2*N)**d_vc+1)/delta))/N)

# Plotting the three bounds
plt.plot(N,vc_bound) #curve in blue
plt.plot(N,Rademacher) #curve in orange
plt.plot(N,Parrondo_Broek) #curve in green
print("The generalization error of vc_bound (blue curve) with N = 10000 is: ", vc_bound[4999])
print("The generalization error of Rademacher (orange curve) with N = 10000 is: ", Rademacher[4999])
print("The generalization error of Parrondo_Broek (green curve) with N = 10000 is: ", Parrondo_Broek[4999])

# the generalization error for Devroye
sample_size = 10000
e = Rademacher[4999] # initialize the error with the generalization error of Rademacher with N = 10000
Devroye = math.sqrt((4*e*(1+e) + math.log(80*(sample_size*100+1)))/(2*sample_size))
while Devroye<e:
    e = Devroye
    Devroye = math.sqrt((4*e*(1+e) + math.log(80*(sample_size*100+1)))/(2*sample_size))
print("The generalization error of Devroye with N = 10000 is: ", Devroye)
if Devroye < Parrondo_Broek[4999]:
    print("This error is smaller than the error of Parrondo_Broek for N = 10000")
    print("Therefore the answer for Question 2 is [d].")

# Question 3
N = 5

# Error of VC_bound for N = 5
vc_bound = math.sqrt(8/N * math.log(4*((2*N)**d_vc+1)/delta))

# Error of Rademacher for N = 5
Rademacher = math.sqrt(2*math.log(2*N*(N**d_vc+1))/N) + math.sqrt(2/N*math.log(1/delta))+1/N

# the generalization error for Parrondo and Van den Broek
e = vc_bound # initialize the error with the generalization error of VC_bound with N = 5
Parrondo_Broek = math.sqrt(1/N*(2*e + math.log(6*((2*N)**d_vc+1)/delta)))
while Parrondo_Broek < e:
#     print("Generalization error of Parrondo_Broek is smaller than your e")
    e = Parrondo_Broek
    Parrondo_Broek = math.sqrt((2*e + math.log(6*((2*N)**d_vc+1)/delta))/N)

# the generalization error for Parrondo and Van den Broek
e = vc_bound # initialize the error with the generalization error of VC_bound with N = 5
Devroye = math.sqrt((4*e*(1+e) + math.log(80*(N**100+1)))/(2*N))
while Devroye<e:
    e = Devroye
    Devroye = math.sqrt((4*e*(1+e) + math.log(80*(N**100+1)))/(2*N))
Error = {"vc_bound":vc_bound,"Rademacher":Rademacher,"Parrondo_Broek":Parrondo_Broek, "Devroye":Devroye}
print(Error)
print("Therefore the answer is [c].")

### BIAS and VARIANCE ###

# Question 4
sample_size = 10000
randnm = pd.DataFrame(np.random.uniform(low = -1, high = 1, size = (sample_size,2)))
a = np.linspace(-5,5,num=1000)
f = np.sin(np.pi*randnm)
slope_list = []
for i in range(sample_size):
    y1 = randnm.loc[i,0]*a
    y2 = randnm.loc[i,1]*a
    sq_error1 = (f.loc[i,0] - y1)**2
    sq_error2 = (f.loc[i,1] - y2)**2
    sum_sq_errors2 = pd.DataFrame(sq_error1 + sq_error2)
    min_index = sum_sq_errors2.idxmin(axis=0)
    best_slope = a[min_index]
    slope_list.append(best_slope)
mean_slope = np.mean(slope_list)
print("Mean slope is: ", mean_slope)
print("Therefore the answer is [e]")

# Question 5
gm = mean_slope * randnm
bias = (gm - np.sin(np.pi*randnm))**2
print("Bias is: ", np.mean(bias.mean(axis=0)))
print("Therefore the answer is [b]")

# Question 6
slopes_df = pd.DataFrame(slope_list)
mean_ED_list = []
for i in range(10000): #iterate through generated data points
    rand_pt1 = float(randnm.loc[i,0])
    rand_pt2 = float(randnm.loc[i,1])
#     for j in range(5): #iterate through best hypothesis each generated with particular data set (two points)
    var_indata1 = pd.DataFrame((slopes_df*rand_pt1 - mean_slope*rand_pt1)**2)
    var_indata2 = pd.DataFrame((slopes_df*rand_pt2 - mean_slope*rand_pt2)**2)
    var_indata = (var_indata1 + var_indata2)/2 #
    mean_ED = np.mean(var_indata) # This should give E[(g_D(x) - g_M(x))**2] over data D
    mean_ED_list.append(mean_ED) # Appending each E_D generated by a particular sample (two points)
Var = np.mean(mean_ED_list) # Averaging mean ED over all data points should give E[E[(g_D(x) - g_M(x))**2]]
print("Variance is: ", Var)
print("Therefore the answer is [a]")

# Question 7

#Let's try [a] h = b
# First get Bias
b_list = []
b = np.linspace(-1,1,num=1000)
for i in range(sample_size):
    sq_error1 = (f.loc[i,0] - b)**2
    sq_error2 = (f.loc[i,1] - b)**2
    sum_sq_errors2 = pd.DataFrame(sq_error1 + sq_error2)
    min_index = sum_sq_errors2.idxmin(axis=0)
    best_b = b[min_index]
    b_list.append(best_b)
mean_b = np.mean(b_list)
bias_x = (mean_b - np.sin(np.pi*randnm))**2
print("Bias is: ", np.mean(bias_x.mean(axis=0)))

# Get Variance
bs_df = pd.DataFrame(b_list)
var = np.mean((bs_df - mean_b)**2)
print("Variance is: ", var)
print("E[Eout] for h(x)=b is: ", np.mean(bias_x.mean(axis=0)) + var)

# Let's compute E[Eout] for [b] h(x) = a*x
EEoutax = np.mean(bias.mean(axis=0)) + Var
print("E[Eout] for h(x)=a*x is: ", EEoutax)

#Let's try [d] h = a*x^2 + b

coeff_list = []
for i in range(sample_size):
    y1 = (randnm.loc[i,0]**2)*a
    y2 = (randnm.loc[i,1]**2)*a
    sq_error1 = (f.loc[i,0] - y1)**2
    sq_error2 = (f.loc[i,1] - y2)**2
    sum_sq_errors2 = pd.DataFrame(sq_error1 + sq_error2)
    min_index = sum_sq_errors2.idxmin(axis=0)
    best_coeff = a[min_index]
    coeff_list.append(best_coeff)
mean_coeff = np.mean(coeff_list)
print("Mean coefficient is: ", mean_coeff)

# Compute Bias
gm_ax2 = mean_coeff * (randnm**2)
bias_ax2 = (gm_ax2 - np.sin(np.pi*randnm))**2
print("Bias is: ", np.mean(bias_ax2.mean(axis=0)))

#Compute Variance
coeff_df = pd.DataFrame(coeff_list)
mean_ED_list = []
for i in range(10000): #iterate through generated data points
    rand_pt1 = float(randnm.loc[i,0])**2
    rand_pt2 = float(randnm.loc[i,1])**2
#     for j in range(5): #iterate through best hypothesis each generated with particular data set (two points)
    var_indata1 = pd.DataFrame((coeff_df*rand_pt1 - mean_slope*rand_pt1)**2)
    var_indata2 = pd.DataFrame((coeff_df*rand_pt2 - mean_slope*rand_pt2)**2)
    var_indata = (var_indata1 + var_indata2)/2 #
    mean_ED = np.mean(var_indata) # This should give E[(g_D(x) - g_M(x))**2] over data D
    mean_ED_list.append(mean_ED) # Appending each E_D generated by a particular sample (two points)
var_ax2 = np.mean(mean_ED_list) # Averaging mean ED over all data points should give E[E[(g_D(x) - g_M(x))**2]]
print("Variance is: ", var_ax2)
print("E[Eout] for h(x)=a*x^2 is: ", np.mean(bias_ax2.mean(axis=0)) + var_ax2)
